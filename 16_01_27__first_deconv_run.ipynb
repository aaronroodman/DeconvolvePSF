{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%connect_info\n",
    "%load_ext Cython\n",
    "%load_ext autoreload\n",
    "%autoreload 2  # 0 disable, 1 for only %aimport objects, 2 for those EXCEPT %aimport\n",
    "\n",
    "# numpy and matplotlib already imported\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import fitsio\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "py.sign_in(\"cpadavis\", \"4oa3kd6g16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expid = 180489\n",
    "kils = False\n",
    "if kils:\n",
    "    # these give the deconvolved stars\n",
    "    deconv_dir = '/afs/slac.stanford.edu/u/ki/swmclau2/Git/DeconvolvePSF/DeconvolvePSF/output/00180489'\n",
    "    # not sure what stars these really are? the combined psfex + deconv?\n",
    "    deconvmodel_loc = '/nfs/slac/g/ki/ki18/des/cpd/180489_stars.npy'\n",
    "    jamierod_results_path = '/nfs/slac/g/ki/ki18/des/cpd/jamierod_results.csv'\n",
    "    mesh_directory = '/nfs/slac/g/ki/ki22/roodman/ComboMeshesv20'\n",
    "    # directory containing the input data files\n",
    "    base_directory = '/nfs/slac/g/ki/ki18/des/cpd/psfex_catalogs/SVA1_FINALCUT/psfcat/'\n",
    "else:\n",
    "    # these give the deconvolved stars\n",
    "    deconv_dir = '/Users/cpd/Desktop/deconvpsf/00180000/00180489/'\n",
    "    # not sure what stars these really are? the combined psfex + deconv?\n",
    "    deconvmodel_loc = '/Users/cpd/Desktop/deconvpsf/00180000/00180489/180489_stars.npy'\n",
    "    jamierod_results_path = '/Users/cpd/Desktop/deconvpsf/jamierod_results.csv'\n",
    "    mesh_directory = '/Users/cpd/Projects/WavefrontPSF/meshes/Science-20121120s1-v20i2'\n",
    "    # directory containing the input data files\n",
    "    base_directory = '/Users/cpd/Desktop/deconvpsf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skeleton for making psf model\n",
    "\n",
    "# this gets you a bunch of stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WavefrontPSF.psf_interpolator import Mesh_Interpolator\n",
    "from WavefrontPSF.wavefront import Wavefront\n",
    "from WavefrontPSF.digestor import Digestor\n",
    "from WavefrontPSF.psf_evaluator import Moment_Evaluator\n",
    "from WavefrontPSF.donutengine import DECAM_Model_Wavefront\n",
    "from glob import glob\n",
    "from itertools import izip\n",
    "from psfex import PSFEx\n",
    "\n",
    "jamierod_results = pd.read_csv(jamierod_results_path)\n",
    "jamierod_results = jamierod_results.set_index('expid')\n",
    "\n",
    "# set up objects. make sure I get the right mesh\n",
    "digestor = Digestor()\n",
    "PSF_Evaluator = Moment_Evaluator()\n",
    "mesh_name = 'Science-20121120s1-v20i2_All'\n",
    "PSF_Interpolator = Mesh_Interpolator(mesh_name=mesh_name, directory=mesh_directory)\n",
    "\n",
    "# This will be our main wavefront\n",
    "WF = DECAM_Model_Wavefront(PSF_Interpolator=PSF_Interpolator)\n",
    "\n",
    "# load up data\n",
    "expid_path = '/{0:08d}/{1:08d}'.format(expid - expid % 1000, expid)\n",
    "data_directory = base_directory + expid_path\n",
    "files = glob(data_directory + '/*{0}'.format('_selpsfcat.fits'))\n",
    "\n",
    "data_df = digestor.digest_fits(files[0], do_exclude=False)\n",
    "meta_hdulist = [fits.open(files[0])] #list of HDULists #META\n",
    "\n",
    "for file in files[1:]:\n",
    "    tmpData = digestor.digest_fits(file,do_exclude=False )\n",
    "    data_df = data_df.append(tmpData)\n",
    "    meta_hdulist.append(fits.open(file))\n",
    "\n",
    "fit_i = jamierod_results.loc[expid]\n",
    "\n",
    "misalignment = {'z04d': fit_i['z04d'], 'z04x': fit_i['z04x'], 'z04y': fit_i['z04y'],\n",
    "                'z05d': fit_i['z05d'], 'z05x': fit_i['z05x'], 'z05y': fit_i['z05y'],\n",
    "                'z06d': fit_i['z06d'], 'z06x': fit_i['z06x'], 'z06y': fit_i['z06y'],\n",
    "                'z07d': fit_i['z07d'], 'z07x': fit_i['z07x'], 'z07y': fit_i['z07y'],\n",
    "                'z08d': fit_i['z08d'], 'z08x': fit_i['z08x'], 'z08y': fit_i['z08y'],\n",
    "                'z09d': fit_i['z09d'], 'z09x': fit_i['z09x'], 'z09y': fit_i['z09y'],\n",
    "                'z10d': fit_i['z10d'], 'z10x': fit_i['z10x'], 'z10y': fit_i['z10y'],\n",
    "                'rzero': fit_i['rzero']}\n",
    "\n",
    "#print(misalignment['rzero'])\n",
    "#rzero needs to be adjusted to be smaller than the stars!\n",
    "x = .3 / .14#4-\n",
    "misalignment['rzero'] = 1 / (1 / misalignment['rzero'] - x)\n",
    "#print(misalignment['rzero'])\n",
    "\n",
    "#print(.14*x )\n",
    "\n",
    "data_df['rzero'] = misalignment['rzero']\n",
    "optpsf, data_df = WF.draw_psf(data_df, misalignment=misalignment)\n",
    "\n",
    "#optPSFStamps is a numpy data cube\n",
    "#full_data is data frame including vignettes of the stars\n",
    "\n",
    "# make the psfex models for both portions\n",
    "psf_files = glob(data_directory + '/*{0}'.format('psfcat_validation_subtracted.psf'))\n",
    "psfdeconv_files = glob(deconv_dir + '/*.psf')\n",
    "\n",
    "atmpsf_list = []\n",
    "psfex_list = []\n",
    "stars = []\n",
    "#TODO Check that files are in the same order as the hdulist\n",
    "for psfex_file, file, hdulist in  izip(psf_files, psfdeconv_files, meta_hdulist):\n",
    "    pex = PSFEx(file)\n",
    "    pex_orig = PSFEx(psfex_file)\n",
    "    for yimage, ximage in izip(hdulist[2].data['YWIN_IMAGE'], hdulist[2].data['XWIN_IMAGE']):\n",
    "        atmpsf = np.zeros((32,32))\n",
    "        #psfex has a tendency to return images of weird and varying sizes\n",
    "        #This scheme ensures that they will all be the same 32x32 by zero padding\n",
    "        #assumes the images are square and smaller than 32x32\n",
    "        #Proof god is real and hates observational astronomers.\n",
    "        atmpsf_small = pex.get_rec(yimage, ximage)\n",
    "        atm_shape = atmpsf_small.shape[0] #assumed to be square\n",
    "        pad_amount = int((32-atmpsf_small.shape[0]) / 2)\n",
    "        atmpsf[pad_amount:32-(pad_amount+atm_shape%2),pad_amount:32-(pad_amount+atm_shape%2) ] = atmpsf_small\n",
    "        atmpsf_list.append(atmpsf)\n",
    "        \n",
    "        atmpsf = np.zeros((32,32))\n",
    "        #psfex has a tendency to return images of weird and varying sizes\n",
    "        #This scheme ensures that they will all be the same 32x32 by zero padding\n",
    "        #assumes the images are square and smaller than 32x32\n",
    "        #Proof god is real and hates observational astronomers.\n",
    "        atmpsf_small = pex_orig.get_rec(yimage, ximage)\n",
    "        atm_shape = atmpsf_small.shape[0] #assumed to be square\n",
    "        pad_amount = int((32-atmpsf_small.shape[0]) / 2)\n",
    "        atmpsf[pad_amount:32-(pad_amount+atm_shape%2),pad_amount:32-(pad_amount+atm_shape%2) ] = atmpsf_small\n",
    "        psfex_list.append(atmpsf)\n",
    "    stars.append(hdulist[2].data['VIGNET'])\n",
    "\n",
    "atmpsf = np.array(atmpsf_list)\n",
    "psfexpsf = np.array(psfex_list)\n",
    "stars = np.array(stars)\n",
    "stars = np.vstack(stars).astype(np.float64)\n",
    "\n",
    "model = np.load(deconvmodel_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stamps_and_combine_with_data(stamps, data):\n",
    "    eval_data = WF.evaluate_psf(stamps)\n",
    "    eval_data.index = data.index\n",
    "    combined_df = eval_data.combine_first(data)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmpsf_df = evaluate_stamps_and_combine_with_data(atmpsf, data_df)\n",
    "psfexpsf_df = evaluate_stamps_and_combine_with_data(psfexpsf, data_df)\n",
    "optpsf_df = evaluate_stamps_and_combine_with_data(optpsf, data_df)\n",
    "model_df = evaluate_stamps_and_combine_with_data(model, data_df)\n",
    "stars_df = evaluate_stamps_and_combine_with_data(stars, data_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "atmpsf # atmospheric piece of deconv stamps\n",
    "psfexpsf # original psfex stamps\n",
    "optpsf # optical model stamps\n",
    "model # atmosphere conv with optical\n",
    "stars # data vignettes\n",
    "\n",
    "optpsf_df # opt psf df\n",
    "misalignment # misalignment dictionary\n",
    "WF # Wavefront object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinekeys = ['e0', 'e1', 'e2', 'E1norm', 'E2norm', 'delta1', 'delta2', 'zeta1', 'zeta2']\n",
    "# make a big df with all the above columns combined\n",
    "df = stars_df.copy()\n",
    "names = ['model', 'psfex', 'opt', 'atm']\n",
    "df_list = [model_df, psfexpsf_df, optpsf_df, atmpsf_df]\n",
    "for key in combinekeys:\n",
    "    # add the other medsub\n",
    "    df['{0}_medsub'.format(key)] = df[key] - df[key].median()\n",
    "    for name, psf in zip(names, df_list):\n",
    "        if key == 'E1norm':\n",
    "            psf[key] = psf['e1'] / psf['e0']\n",
    "        elif key == 'E2norm':\n",
    "            psf[key] = psf['e2'] / psf['e0']\n",
    "        df['{0}_{1}'.format(name, key)] = psf[key]\n",
    "        # add medsub\n",
    "        df['{0}_{1}_medsub'.format(name, key)] = df['{0}_{1}'.format(name, key)] - df['{0}_{1}'.format(name, key)].median()\n",
    "        df['{0}_{1}_diff'.format(name, key)] = df['{0}_{1}'.format(name, key)] - df[key]\n",
    "        df['{0}_{1}_medsub_diff'.format(name, key)] = df['{0}_{1}_medsub'.format(name, key)] - df['{0}_medsub'.format(key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can play with this value to make the binning more or less fine\n",
    "WF = Wavefront(model=df, num_bins=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the wavefronts in terms of the moments for the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wavefront(key):\n",
    "    \n",
    "    # set a and b vmin and vmax\n",
    "    cutoff_percent = 5\n",
    "    mins = [np.percentile(WF.field[key], cutoff_percent)] + \\\n",
    "           [np.percentile(WF.field['{0}_{1}'.format(name, key)], cutoff_percent) for name in names]\n",
    "    maxs = [np.percentile(WF.field[key], 100 - cutoff_percent)] + \\\n",
    "           [np.percentile(WF.field['{0}_{1}'.format(name, key)], 100 - cutoff_percent) for name in names]\n",
    "    a = min(mins)\n",
    "    b = max(maxs)\n",
    "    \n",
    "    nrows = 3\n",
    "    ncols = 2\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10 * ncols, 5 * nrows))\n",
    "    ax = WF.prep_axis(axs.flatten()[0])\n",
    "    WF.plot_field(key, fig=fig, ax=ax, a=a, b=b)\n",
    "    ax.set_title('stars')\n",
    "    for name_i, name in enumerate(names, start=1):\n",
    "        ax = WF.prep_axis(axs.flatten()[name_i])\n",
    "        WF.plot_field('{0}_{1}'.format(name, key), fig=fig, ax=ax, a=a, b=b)\n",
    "        ax.set_title(name)\n",
    "        \n",
    "    # have an extra!\n",
    "    axs.flatten()[-1].set_axis_off()\n",
    "ipywidgets.interact(plot_wavefront, key=combinekeys + [key + '_medsub' for key in combinekeys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot wavefront - data, psfex - data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wavefront_diff(key):\n",
    "    \n",
    "    # set a and b vmin and vmax\n",
    "    cutoff_percent = 5\n",
    "    mins = [np.percentile(WF.field['{0}_{1}_diff'.format(name, key)], cutoff_percent) for name in names]\n",
    "    maxs = [np.percentile(WF.field['{0}_{1}_diff'.format(name, key)], 100 - cutoff_percent) for name in names]\n",
    "    a = min(mins)\n",
    "    b = max(maxs)\n",
    "    \n",
    "    nrows = 2\n",
    "    ncols = 1\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20 * ncols, 10 * nrows))\n",
    "    for name_i, name in enumerate(['model', 'psfex']):\n",
    "        ax = WF.prep_axis(axs.flatten()[name_i])\n",
    "        WF.plot_field('{0}_{1}_diff'.format(name, key), fig=fig, ax=ax, a=a, b=b)\n",
    "        ax.set_title(name)\n",
    "ipywidgets.interact(plot_wavefront_diff, key=combinekeys + [key + '_medsub' for key in combinekeys])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "atmpsf # atmospheric piece of deconv stamps\n",
    "psfexpsf # original psfex stamps\n",
    "optpsf # optical model stamps\n",
    "model # atmosphere conv with optical\n",
    "stars # data vignettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_stars(indx):\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8 * ncols, 6 * nrows))\n",
    "    names = ['star', 'model', 'psfex', 'opt', 'atm']\n",
    "    stamps = [stars, model, psfexpsf, optpsf, atmpsf]\n",
    "    for ith, name, stamp in zip(range(len(names)), names, stamps):\n",
    "        ax = axs.flatten()[ith]\n",
    "        star = stamp[indx].copy()\n",
    "        star = np.where(star < -1e10, 0, star)\n",
    "        star /= star.sum()\n",
    "#         star = np.log10(star)\n",
    "        IM = ax.imshow(star, cmap=plt.cm.RdBu_r)\n",
    "        fig.colorbar(IM, ax=ax)\n",
    "        ax.set_title('{0} {1}'.format(name, indx))\n",
    "    # have an extra!\n",
    "    axs.flatten()[-1].set_axis_off()\n",
    "ipywidgets.interact(view_stars, indx=(0, len(stars), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}